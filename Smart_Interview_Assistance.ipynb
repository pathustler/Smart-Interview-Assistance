{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 3 - NLP Project - Group 1 Wednesday Morning:**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Y01WtcQSAZlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "\n",
        "---\n",
        "\n",
        "Effective communication is a critical skill in professional settings, especially during job interviews. Candidates are often evaluated not just on the content of their responses but also on their delivery; grammar, tone, clarity, and overall professionalism. However, providing objective, consistent feedback on interview responses can be challenging for recruiters and job seekers alike.\n",
        "\n",
        ".\n",
        "\n",
        "**Why Smart Interview Assistance Matters**\n",
        "\n",
        "Automated interview assistance tools can help candidates improve their speaking skills by providing constructive feedback on their responses. Such systems offer several key benefits:\n",
        "\n",
        "\n",
        "\n",
        "*   **Objective Evaluation:** Eliminates human biases by offering consistent scoring criteria.\n",
        "\n",
        "*   **Personalised Feedback:** Highlights individual strengths and areas for improvement.\n",
        "*   **Skill Development:** Helps candidates refine their responses, improve articulation, and reduce filler word usage.\n",
        "*   **Scalable Solution:** Enables large-scale interview preparation without the need for human reviewers.\n",
        "\n",
        ".\n",
        "\n",
        "**The Problem We Are Solving**\n",
        "\n",
        "Job seekers often struggle with articulating professional responses in interviews. Common issues include:\n",
        "*   Overuse of filler words (e.g., \"um\", \"like\", \"you know\").\n",
        "\n",
        "*   Poor grammar and sentence structure.\n",
        "*   Negative or uncertain tone.\n",
        "*   Lack of vocabulary diversity.\n",
        "\n",
        ".\n",
        "\n",
        "**Proposed Solution**\n",
        "\n",
        "Our Smart Interview Assistance project leverages Natural Language Processing (NLP) and machine learning to analyse interview responses and provide professionalism scores. The core steps include:\n",
        "\n",
        "* **Data Preprocessing:** Cleaning and preparing textual data for analysis.\n",
        "\n",
        "* **Feature Extraction:** Extracting linguistic features such as sentiment scores, lexical diversity, grammar issues, and filler word counts.\n",
        "\n",
        "* **Model Training:** Using machine learning algorithms (e.g., Logistic Regression, Random Forest) to predict professionalism scores.\n",
        "\n",
        "* **Evaluation & Feedback:** Assessing model performance and generating actionable feedback for users.\n"
      ],
      "metadata": {
        "id": "CszMOpidAla5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "bJh0axXLAkk3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV dataset from Google Drive\n",
        "df = pd.read_csv('/content/drive/MyDrive/RatedInterviewQuestionsDataset.csv')\n",
        "\n",
        "# Drop index column if it exists (some CSVs export an unnamed index column)\n",
        "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "\n",
        "# Display dataset shape and basic info\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "print(df.head(3))\n",
        "print(df['professionalism_rating'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-03hK4F55MrV",
        "outputId": "777ae429-cf18-473d-8397-bf343727c690"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(200, 3)\n",
            "Index(['question', 'answer', 'professionalism_rating'], dtype='object')\n",
            "                                            question  \\\n",
            "0  How do you stay motivated during repetitive ta...   \n",
            "1  What skills do you hope to develop in your nex...   \n",
            "2  How do you deal with feedback that you disagre...   \n",
            "\n",
            "                                              answer  professionalism_rating  \n",
            "0  Well, you know, repetitive tasks, they're just...                     0.0  \n",
            "1  Well, that's a great question! Honestly, I hav...                     0.0  \n",
            "2  When faced with conflict, I approach it calmly...                     1.0  \n",
            "professionalism_rating\n",
            "0.0    100\n",
            "1.0    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # Import regular expressions library\n",
        "\n",
        "# Function to preprocess text data\n",
        "def preprocess_text(text: str) -> str:\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Replace newlines with space\n",
        "    text = re.sub(r'[\\n\\r]+', ' ', text)\n",
        "\n",
        "    # Remove punctuation characters\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "    # Normalize multiple spaces to single space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to dataset column 'answer' and store in new column 'clean_answer'\n",
        "df['clean_answer'] = df['answer'].apply(preprocess_text)\n",
        "\n",
        "# Print original and cleaned text for comparison\n",
        "print(df['answer'].iloc[0], \"\\n--> \\n\", df['clean_answer'].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXGczHju71GF",
        "outputId": "ae66891e-0a9d-4852-8598-59ec4892b48b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well, you know, repetitive tasks, they're just...there. You gotta do them, right? I try to just, like, get them over with. Honestly, sometimes I zone out a bit. It's not ideal, I know, but it helps. I listen to music, usually something upbeat, to keep me from falling asleep.\r\n",
            "\r\n",
            "And coffee! Lots of coffee. Gotta keep that caffeine flowing, haha! Sometimes, I just tell myself it's temporary, you know? Just a little blip on the radar. I think about the bigger picture, maybe, like the end result. Or I just daydream.\r\n",
            "\r\n",
            "Honestly, I haven't really figured out the perfect system yet. I kinda wing it. I'm a pretty adaptable person though, so I manage. Hopefully, the task doesn't last too long. And if it does, well, I just push through. \n",
            "--> \n",
            " well you know repetitive tasks theyre justthere you gotta do them right i try to just like get them over with honestly sometimes i zone out a bit its not ideal i know but it helps i listen to music usually something upbeat to keep me from falling asleep and coffee lots of coffee gotta keep that caffeine flowing haha sometimes i just tell myself its temporary you know just a little blip on the radar i think about the bigger picture maybe like the end result or i just daydream honestly i havent really figured out the perfect system yet i kinda wing it im a pretty adaptable person though so i manage hopefully the task doesnt last too long and if it does well i just push through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the list of available packages and their versions\n",
        "!apt-get update\n",
        "\n",
        "# Install OpenJDK 17 (Java Development Kit version 17) without asking for confirmation (-y flag)\n",
        "!apt-get install -y openjdk-17-jdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrr1dF3A9GlQ",
        "outputId": "b3c9f112-5090-403f-b0e8-d443de6adb55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-17-jdk is already the newest version (17.0.15+6~us1-0ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 89 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import needed libraries\n",
        "# !pip install spacy nltk language_tool_python textstat vaderSentiment\n",
        "\n",
        "import nltk, spacy, language_tool_python, textstat\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download spaCy English model and NLTK data\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')  # Load small English model\n",
        "except:\n",
        "    spacy.cli.download('en_core_web_sm')  # Download if not present\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "nltk.download('punkt')  # Download tokenizer data for NLTK if needed\n",
        "\n",
        "# Initialize sentiment analyzer and grammar tool\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "tool = language_tool_python.LanguageTool('en-US')  # Grammar checker tool\n",
        "\n",
        "# List of filler words to track\n",
        "filler_words = [\"um\", \"uh\", \"like\", \"you know\", \"actually\", \"basically\",\n",
        "                \"literally\", \"i mean\", \"hmm\", \"ah\", \"ok so\"]\n",
        "\n",
        "# Function to extract features from text\n",
        "def extract_features(text: str) -> dict:\n",
        "    original_text = text  # Preserve original text\n",
        "    clean_text = preprocess_text(text)  # Apply text preprocessing\n",
        "\n",
        "    # 1. Sentiment score (compound value)\n",
        "    compound = sentiment_analyzer.polarity_scores(original_text)['compound']\n",
        "\n",
        "    # 2. Lexical diversity (unique words / total words)\n",
        "    tokens = [tok for tok in clean_text.split() if tok.isalpha()]\n",
        "    lex_div = len(set(tokens)) / len(tokens) if tokens else 0\n",
        "\n",
        "    # 3. Grammar issue count\n",
        "    matches = tool.check(original_text)\n",
        "    gram_issues = len([m for m in matches if m.ruleId not in {\"PUNCTUATION\", \"WHITESPACE_RULE\"}])\n",
        "\n",
        "    # 4. Flesch readability score (ease of reading metric)\n",
        "    flesch_score = textstat.flesch_reading_ease(original_text)\n",
        "\n",
        "    # 5. Filler word count\n",
        "    filler_count = 0\n",
        "    for f in filler_words:\n",
        "        filler_count += len(re.findall(rf'\\b{re.escape(f)}\\b', clean_text))\n",
        "\n",
        "    # 6. Part-of-Speech (POS) counts using spaCy\n",
        "    doc = nlp(original_text)\n",
        "    pos_counts = {\"NOUN\": 0, \"VERB\": 0, \"ADJ\": 0, \"ADV\": 0, \"PRON\": 0, \"INTJ\": 0}\n",
        "\n",
        "    for token in doc:\n",
        "        if token.pos_ in pos_counts:\n",
        "            # Treat proper nouns as general nouns\n",
        "            if token.pos_ == \"PROPN\":\n",
        "                pos_counts[\"NOUN\"] += 1\n",
        "            else:\n",
        "                pos_counts[token.pos_] += 1\n",
        "\n",
        "    # Aggregate all features into a dictionary\n",
        "    features = {\n",
        "        'sentiment': compound,\n",
        "        'lexical_diversity': lex_div,\n",
        "        'grammar_errors': gram_issues,\n",
        "        'readability': flesch_score,\n",
        "        'filler_count': filler_count,\n",
        "        'noun_count': pos_counts['NOUN'],\n",
        "        'verb_count': pos_counts['VERB'],\n",
        "        'adj_count': pos_counts['ADJ'],\n",
        "        'adv_count': pos_counts['ADV'],\n",
        "        'pronoun_count': pos_counts['PRON'],\n",
        "        'interjection_count': pos_counts['INTJ']\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction function to each answer in DataFrame\n",
        "feature_rows = []\n",
        "for ans in df['answer']:\n",
        "    feature_rows.append(extract_features(ans))\n",
        "\n",
        "# Convert extracted features to DataFrame\n",
        "features_df = pd.DataFrame(feature_rows)\n",
        "\n",
        "# Add professionalism rating column to features DataFrame\n",
        "features_df['professionalism'] = df['professionalism_rating']\n",
        "\n",
        "# Preview first 5 rows of the final features DataFrame\n",
        "print(features_df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWd6OG0Q8hQL",
        "outputId": "d172e144-4441-41c6-816f-2f82f7a80925"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sentiment  lexical_diversity  grammar_errors  readability  filler_count  \\\n",
            "0     0.9867           0.700000               2    78.680928             4   \n",
            "1     0.9689           0.666667               0    82.550769             8   \n",
            "2    -0.0772           0.896552               0    60.841638             0   \n",
            "3     0.7964           0.904762               0    18.920357             0   \n",
            "4     0.9941           0.554622               1    89.092660            10   \n",
            "\n",
            "   noun_count  verb_count  adj_count  adv_count  pronoun_count  \\\n",
            "0          16          25         10         21             26   \n",
            "1          14          24         12         11             27   \n",
            "2           4           7          0          2              5   \n",
            "3           3           3          2          2              3   \n",
            "4          10          24         14         13             26   \n",
            "\n",
            "   interjection_count  professionalism  \n",
            "0                   3              0.0  \n",
            "1                   7              0.0  \n",
            "2                   0              1.0  \n",
            "3                   0              1.0  \n",
            "4                   5              0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-stubs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4Cx1EnrQFfG",
        "outputId": "496474a6-67e7-4f77-bd36-ac4d258e3edd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-stubs (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-stubs\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets (80/20 split)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df['clean_answer'].values\n",
        "y = df['professionalism_rating'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize text and convert to sequences of integers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)  # fit on training text to build vocabulary\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq  = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences to a uniform length (use the max length from training data)\n",
        "max_len = max(len(seq) for seq in X_train_seq)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad  = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# Determine vocabulary size for the embedding layer\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary size:\", vocab_size, \"| Sequence length:\", max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzECynAGPTg1",
        "outputId": "c7209e20-97c6-4f8b-fc69-c994540092f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1306 | Sequence length: 145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Build a simple LSTM regression model\n",
        "embedding_dim = 100  # dimension for word embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with MSE loss and MAE metric\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "x4T1BpTYPhoz",
        "outputId": "2c47ca31-7df4-46d3-cc84-bee13d137a78"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training set\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "history = model.fit(X_train_pad, y_train, epochs=epochs, batch_size=batch_size, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UmdBCllPmsG",
        "outputId": "298430d0-5431-44a0-f98e-a416d1bf3beb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 - 4s - 413ms/step - loss: 0.2545 - mae: 0.5012\n",
            "Epoch 2/10\n",
            "10/10 - 1s - 79ms/step - loss: 0.2211 - mae: 0.4642\n",
            "Epoch 3/10\n",
            "10/10 - 1s - 52ms/step - loss: 0.1076 - mae: 0.2684\n",
            "Epoch 4/10\n",
            "10/10 - 1s - 53ms/step - loss: 0.0934 - mae: 0.2171\n",
            "Epoch 5/10\n",
            "10/10 - 1s - 51ms/step - loss: 0.0573 - mae: 0.1775\n",
            "Epoch 6/10\n",
            "10/10 - 1s - 54ms/step - loss: 0.0327 - mae: 0.1419\n",
            "Epoch 7/10\n",
            "10/10 - 1s - 52ms/step - loss: 0.0081 - mae: 0.0837\n",
            "Epoch 8/10\n",
            "10/10 - 1s - 53ms/step - loss: 0.0041 - mae: 0.0617\n",
            "Epoch 9/10\n",
            "10/10 - 1s - 61ms/step - loss: 0.0019 - mae: 0.0418\n",
            "Epoch 10/10\n",
            "10/10 - 1s - 54ms/step - loss: 0.0011 - mae: 0.0330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to predict on the test set\n",
        "y_pred = model.predict(X_test_pad).flatten()\n",
        "\n",
        "# Calculate evaluation metrics: MAE, RMSE, and R^2\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "print(f\"Test R^2: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtMXVcMVQMLJ",
        "outputId": "ab13e9ed-8b7a-4a99-9096-c978a749865e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628ms/step\n",
            "Test MAE: 0.0297\n",
            "Test RMSE: 0.0301\n",
            "Test R^2: 0.9963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Build a small DataFrame of test answers with actual vs predicted\n",
        "test_df = pd.DataFrame({\n",
        "    'clean_answer': X_test,      # your test answers\n",
        "    'actual_rating': y_test,     # true scores\n",
        "    'predicted_rating': y_pred   # model predictions\n",
        "})\n",
        "\n",
        "# 2. Merge back to get the original question and original (uncleaned) answer\n",
        "test_df = test_df.merge(\n",
        "    df[['clean_answer', 'question', 'answer']],\n",
        "    on='clean_answer',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 3. Reorder/display the first few rows\n",
        "display(\n",
        "    test_df[['question', 'answer', 'actual_rating', 'predicted_rating']].head(10)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Zb0iY8ulRzK4",
        "outputId": "7a761d58-1386-4680-cc71-60af82995ab1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  How do you respond when a teammate isn't pulli...   \n",
              "1  How do you respond when a teammate isn't pulli...   \n",
              "2  What are your expectations from leadership in ...   \n",
              "3      How does this role fit into your career path?   \n",
              "4      How does this role fit into your career path?   \n",
              "5              Where do you see yourself in 5 years?   \n",
              "6              Where do you see yourself in 5 years?   \n",
              "7              Where do you see yourself in 5 years?   \n",
              "8              Where do you see yourself in 5 years?   \n",
              "9  What would you do if you disagreed with your m...   \n",
              "\n",
              "                                              answer  actual_rating  \\\n",
              "0  Okay, so if someone's slacking, that's, like, ...            0.0   \n",
              "1  Okay, so like, if someone's slacking, it's not...            0.0   \n",
              "2  Well, I guess, like, leadership, right? It's i...            0.0   \n",
              "3  My long-term goal is to grow into a senior rol...            1.0   \n",
              "4  My long-term goal is to grow into a senior rol...            1.0   \n",
              "5  My long-term goal is to grow into a senior rol...            1.0   \n",
              "6  My long-term goal is to grow into a senior rol...            1.0   \n",
              "7  My long-term goal is to grow into a senior rol...            1.0   \n",
              "8  My long-term goal is to grow into a senior rol...            1.0   \n",
              "9  When faced with conflict, I approach it calmly...            1.0   \n",
              "\n",
              "   predicted_rating  \n",
              "0          0.038998  \n",
              "1          0.034559  \n",
              "2          0.035289  \n",
              "3          0.974177  \n",
              "4          0.974177  \n",
              "5          0.974233  \n",
              "6          0.974233  \n",
              "7          0.974233  \n",
              "8          0.974233  \n",
              "9          0.974408  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f83a3f45-5abf-4611-b040-dc8bbfa2f486\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>actual_rating</th>\n",
              "      <th>predicted_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do you respond when a teammate isn't pulli...</td>\n",
              "      <td>Okay, so if someone's slacking, that's, like, ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How do you respond when a teammate isn't pulli...</td>\n",
              "      <td>Okay, so like, if someone's slacking, it's not...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are your expectations from leadership in ...</td>\n",
              "      <td>Well, I guess, like, leadership, right? It's i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How does this role fit into your career path?</td>\n",
              "      <td>My long-term goal is to grow into a senior rol...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does this role fit into your career path?</td>\n",
              "      <td>My long-term goal is to grow into a senior rol...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Where do you see yourself in 5 years?</td>\n",
              "      <td>My long-term goal is to grow into a senior rol...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Where do you see yourself in 5 years?</td>\n",
              "      <td>My long-term goal is to grow into a senior rol...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Where do you see yourself in 5 years?</td>\n",
              "      <td>My long-term goal is to grow into a senior rol...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Where do you see yourself in 5 years?</td>\n",
              "      <td>My long-term goal is to grow into a senior rol...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What would you do if you disagreed with your m...</td>\n",
              "      <td>When faced with conflict, I approach it calmly...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974408</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f83a3f45-5abf-4611-b040-dc8bbfa2f486')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f83a3f45-5abf-4611-b040-dc8bbfa2f486 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f83a3f45-5abf-4611-b040-dc8bbfa2f486');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9b88486-8fb3-4690-be87-7b6406dacb88\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9b88486-8fb3-4690-be87-7b6406dacb88')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9b88486-8fb3-4690-be87-7b6406dacb88 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What are your expectations from leadership in a company?\",\n          \"What would you do if you disagreed with your manager?\",\n          \"How does this role fit into your career path?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Okay, so if someone's slacking, that's, like, a real problem, right? I mean, we're a team, and everyone needs to contribute. Honestly, it depends on the person. Sometimes, I'd just, like, passively-aggressively mention it. You know, little comments like, \\\"Wow, you seem really relaxed today!\\\" or \\\"Is everything okay?\\\". That usually gets the point across, maybe. \\r\\n\\r\\nIf that doesn't work, I might talk to them, you know, but not, like, directly confrontational. More like a casual chat about workload. I'd say something general, like, \\\"Hey, maybe you missed something?\\\" It also depends on the situation. If it's a super important project, I'd probably tell my boss or someone. But yeah, it just depends. I try to keep things chill, I guess.\",\n          \"Okay, so like, if someone's slacking, it's not ideal, right? I usually just... notice. I'm pretty good at picking up on that stuff. I mean, you can tell, can't you? Like, if they're not contributing, you see it in the finished product, or you just... feel it. \\r\\n\\r\\nHonestly, I don't really know what I'd do, specifically. Maybe I'd, like, hint at it, maybe by making a comment about the workload being uneven? Or, I might just let it slide if it's not *that* big a deal, cause conflict isn't fun. Ultimately it depends on the person, the task and how I'm feeling that day, I guess. I am sure my boss will figure it out. I am sure it will all work out, eventually.\",\n          \"When faced with conflict, I approach it calmly and try to understand all perspectives before finding a solution together. What would you do if you disagreed with your manager?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48304589153964794,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_rating\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.038997601717710495,\n          0.03455923870205879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}